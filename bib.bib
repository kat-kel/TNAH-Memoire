
@unpublished{almasDistributedTextServices2021,
  title = {Distributed {{Text Services}} ({{DTS}}): A {{Community-built API}} to {{Publish}} and {{Consume Text Collections}} as {{Linked Data}}},
  shorttitle = {Distributed {{Text Services}} ({{DTS}})},
  author = {Almas, Bridget and Clérice, Thibault and Cayless, Hugh and Jolivet, Vincent and Liuzzo, Pietro Maria and Romanello, Matteo and Robie, Jonathan and Scott, Ian W.},
  date = {2021-03},
  url = {https://hal.archives-ouvertes.fr/hal-03183886},
  urldate = {2022-08-19},
  abstract = {The paper presents the Distributed Text Service API Specification, a community-built effort to facilitate the publication and consumption of texts and their structures as Linked Data. DTS was designed to be as generic as possible, providing simple operations for navigating collections, navigating within a text and retrieving textual content. While the DTS API uses JSON-LD as the serialization format for non-textual data (e.g. descriptive metadata), TEI XML was chosen as the minimum required format for textual data served by the API, in order to guarantee the interoperability of data published by DTS-compliant repositories. The paper describes the DTS API specifications by means of real-world examples, discusses the key design choices that were made, and concludes by providing a list of existing repositories and libraries that support DTS.},
  keywords = {API Specification,FAIR,Interoperability,Text Navigation},
  file = {/Users/kellychristensen/Zotero/storage/5JC8VERD/Almas et al. - 2021 - Distributed Text Services (DTS) a Community-built.pdf}
}

@inproceedings{bawdenAutomaticNormalisationEarly2022,
  title = {Automatic {{Normalisation}} of {{Early Modern French}}},
  author = {Bawden, Rachel and Poinhos, Jonathan and Kogkitsidou, Eleni and Gambette, Philippe and Sagot, Benoît and Gabay, Simon},
  date = {2022-06-20},
  doi = {10.5281/zenodo.5865428},
  url = {https://hal.inria.fr/hal-03540226},
  urldate = {2022-08-11},
  abstract = {Spelling normalisation is a useful step in the study and analysis of historical language texts, whether it is manual analysis by experts or automatic analysis using downstream natural language processing (NLP) tools. Not only does it help to homogenise the variable spelling that often exists in historical texts, but it also facilitates the use of off-the-shelf contemporary NLP tools, if contemporary spelling conventions are used for normalisation. We present FREEMnorm, a new benchmark for the normalisation of Early Modern French (from the 17th century) into contemporary French and provide a thorough comparison of three different normalisation methods: ABA, an alignment-based approach and MT-approaches, (both statistical and neural), including extensive parameter searching, which is often missing in the normalisation literature.},
  eventtitle = {{{LREC}} 2022 - 13th {{Language Resources}} and {{Evaluation Conference}}},
  langid = {english},
  file = {/Users/kellychristensen/Zotero/storage/HP9DRF4T/Bawden et al. - 2022 - Automatic Normalisation of Early Modern French.pdf;/Users/kellychristensen/Zotero/storage/88Z9FP2G/hal-03540226.html}
}

@report{bibliothequenationaledefranceRapportActivite20212022,
  title = {Rapport d'activité 2021 de la Bibliothèque nationale de France},
  author = {{Bibliothèque nationale de France}},
  date = {2022-07-01},
  location = {{Paris, France}},
  url = {https://www.bnf.fr/fr/bnf-rapport-dactivite-2021},
  urldate = {2022-08-09},
  abstract = {La Bibliothèque nationale de France (BnF) a publié début juillet son rapport d'activité 2021, dans un contexte marqué par la réouverture du quadrilatère Richelieu prévue en septembre 2022 et après plusieurs confinements liés à la pandémie du Covid.},
  langid = {french},
  file = {/Users/kellychristensen/Zotero/storage/T96I82ZG/70680-rapport-d-activite-2021-de-la-bibliotheque-nationale-de-france.html}
}

@inreference{bobichonCaviarder2011,
  title = {Caviarder},
  booktitle = {Codicologia},
  author = {Bobichon, Philippe},
  date = {2011},
  publisher = {{Institut de recherche et d'histoire des textes}},
  url = {http://codicologia.irht.cnrs.fr/theme/liste_theme/413#tr-868},
  urldate = {2022-07-25}
}

@article{bobichonLexiconMisePage2009,
  title = {Le Lexicon : {{Mise}} En Page et Mise En Texte Des Manuscrits Hébreux, Grecs, Latins, Romans et Arabes},
  shorttitle = {Le Lexicon},
  author = {Bobichon, Philippe},
  date = {2009},
  pages = {81},
  url = {https://cel.archives-ouvertes.fr/cel-00377671},
  urldate = {2022-07-25},
  abstract = {Le lexicon est une publication pédagogique proposant une vue d'ensemble des dispositifs élaborés dans différentes traditions linguistiques et culturelles (domaines latin, roman, grec, hébreu et arabe) pour la mise en page et la « mise en texte » des manuscrits. Ce dossier pédagogique est le fruit des ateliers animés, depuis 2003, dans le cadre du stage d'initiation au manuscrit médiéval proposé chaque automne par l'IRHT.{$<$}br{$>$}Il propose une vue d'ensemble des dispositifs élaborés dans différentes traditions linguistiques et culturelles pour la mise en page et la « mise en texte » des manuscrits.{$<$}br{$><$}br{$>$}Bien avant l'invention de l'imprimerie et des outils modernes d'édition, les scribes de l'Antiquité et du Moyen Âge furent confrontés à une série de problèmes qui sont indépendants de l'époque, du milieu culturel, du champ linguistique et du sens de l'écriture : comment favoriser la consultation des textes ? Comment rendre aisément perceptible leur structure, la hiérarchie des éléments qui les constituent, leurs articulations ? Comment mettre en valeur des passages particulièrement remarquables, maintenir une certaine proximité entre le texte et son/ses commentaires(s), disposer les illustrations, signaler erreurs, interpolations, omissions ou emprunts, introduire diverses corrections ?{$<$}br{$><$}br{$>$}L'acuité de ces questions s'est accentuée à mesure que la lecture, dans un premier temps réservée à une élite et pratiquée le plus souvent à haute voix, devenait une activité silencieuse et plus largement répandue. Les solutions mises en œuvre dans les différentes traditions manuscrites obéissent à des considérations pratiques et esthétiques. Leur confrontation met en évidence certaines spécificités, mais aussi des similitudes qui rendent très vraisemblables, en ce domaine comme ailleurs, emprunts et influences. {$<$}br{$><$}br{$>$}Cette confrontation a semblé d'autant plus riche d'enseignements que les questions relatives à la « mise en scène » des manuscrits, se situent au carrefour de l'analyse codicologique, paléographique, et textuelle. Or, dans les travaux consacrés aux différentes traditions manuscrites, elles n'occupent le plus souvent qu'une place annexe, ne donnant lieu qu'à des remarques sporadiques. De ce point de vue, l'ouvrage publié en 1990 sous la direction de H.-J. Martin et J. Vezin (cf. bibliographie), dont ce dossier s'inspire en grande partie, fait exception.{$<$}br{$><$}br{$>$}L'approche comparative adoptée ici est analogue à celle qui structure l'ouvrage récemment publié par l'IRHT, sous la direction de Paul Géhin : Lire le manuscrit médiéval, Paris, 2005 (cf. bibliographie). Elle correspond plus généralement à l'ensemble des travaux entrepris dans le cadre de l'IRHT, dont les résultats ouvrent de nombreuses pistes de recherche.},
  langid = {english},
  file = {/Users/kellychristensen/Zotero/storage/XSTWB7G2/Bobichon - 2009 - Le lexicon  Mise en page et mise en texte de.pdf;/Users/kellychristensen/Zotero/storage/NH524NHG/cel-00377671.html}
}

@article{brunetCeQuFaut1987,
  title = {Ce qu’il faut savoir du lecteur optique : l’ancien et le nouveau},
  shorttitle = {Ce qu’il faut savoir du lecteur optique},
  author = {Brunet, Étienne},
  date = {1987},
  journaltitle = {Le médiéviste et l'ordinateur},
  volume = {17},
  number = {1},
  pages = {2--5},
  publisher = {{Persée - Portail des revues scientifiques en SHS}},
  doi = {10.3406/medio.1987.1153},
  url = {https://www.persee.fr/doc/medio_0223-3843_1987_num_17_1_1153},
  urldate = {2022-08-02},
  langid = {fre},
  file = {/Users/kellychristensen/Zotero/storage/G2QCCMQL/medio_0223-3843_1987_num_17_1_1153.html}
}

@article{campsCorpusModelsLemmatisation2021,
  title = {Corpus and {{Models}} for {{Lemmatisation}} and {{POS-tagging}} of {{Classical French Theatre}}},
  author = {Camps, Jean-Baptiste and Gabay, Simon and Fièvre, Paul and Clérice, Thibault and Cafiero, Florian},
  date = {2021-02-14},
  journaltitle = {Journal of Data Mining \& Digital Humanities},
  volume = {2021},
  eprint = {2005.07505},
  eprinttype = {arxiv},
  primaryclass = {cs},
  pages = {6485},
  issn = {2416-5999},
  doi = {10.46298/jdmdh.6485},
  url = {http://arxiv.org/abs/2005.07505},
  urldate = {2022-08-09},
  abstract = {This paper describes the process of building an annotated corpus and training models for classical French literature, with a focus on theatre, and particularly comedies in verse. It was originally developed as a preliminary step to the stylometric analyses presented in Cafiero and Camps [2019]. The use of a recent lemmatiser based on neural networks and a CRF tagger allows to achieve accuracies beyond the current state-of-the art on the in-domain test, and proves to be robust during out-of-domain tests, i.e.up to 20th c.novels.},
  archiveprefix = {arXiv},
  issue = {Digital humanities in...},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/kellychristensen/Zotero/storage/9989KBNC/Camps et al. - 2021 - Corpus and Models for Lemmatisation and POS-taggin.pdf;/Users/kellychristensen/Zotero/storage/8CDAEBBJ/2005.html}
}

@article{carlinBnFDataLabService2021,
  title = {Le {{BnF DataLab}}, Un Service Aux Chercheurs En Humanités Numériques},
  author = {Carlin, Marie and Laborderie, Arnaud},
  date = {2021-12},
  journaltitle = {Humanités numériques},
  volume = {4},
  publisher = {{Bruxelles: Humanistica}},
  url = {https://hal-bnf.archives-ouvertes.fr/hal-03285816},
  urldate = {2022-08-11},
  keywords = {Archives de l'Internet,Bibliothèque numérique,Collections numériques,Digital Collections,Digital Humanities,Digital Library,Digitization,French Internet Archives,Humanités numériques,Numérisation},
  file = {/Users/kellychristensen/Zotero/storage/N336RTS2/Carlin and Laborderie - 2021 - Le BnF DataLab, un service aux chercheurs en human.pdf}
}

@software{chagueHTRUnitedHtrunitedV02022,
  title = {{{HTR-United}}/Htr-United: V0.1.28},
  shorttitle = {{{HTR-United}}/Htr-United},
  author = {Chagué, Alix and Clérice, Thibault and Biay, Sébastien and CVidalG and FloChiff and Vlachou, Matenia and Jacsont, Pauline and Phillip and Constum, Thomas and Hodel, Tobias},
  date = {2022-08-10},
  doi = {10.5281/zenodo.6979746},
  url = {https://zenodo.org/record/6979746},
  urldate = {2022-08-12},
  abstract = {Version 0.1.28 What's Changed Create editer-la-correspondance-de-constance-de-salm-1767-1845.yml by @sbiay in https://github.com/HTR-United/htr-united/pull/77 New Contributors @sbiay made their first contribution in https://github.com/HTR-United/htr-united/pull/77 Full Changelog: https://github.com/HTR-United/htr-united/compare/v0.1.27...v0.1.28},
  organization = {{Zenodo}},
  file = {/Users/kellychristensen/Zotero/storage/FJE6S5UR/6979746.html}
}

@article{chagueHTRUnitedManuMcFrench2022,
  title = {{{HTR-United}} - {{Manu McFrench V1}} ({{Manuscripts}} of {{Modern}} and {{Contemporaneous French}})},
  author = {Chagué, Alix and Clérice, Thibault},
  date = {2022-06-17},
  publisher = {{Zenodo}},
  doi = {10.5281/zenodo.6657809},
  url = {https://zenodo.org/record/6657809},
  urldate = {2022-08-12},
  abstract = {Data were used from all French evenly mixed repository in HTR-United where images and transcription were readily available. Only the data from the 1600 to 2100 were used. 100 pages of Spanish Letters (19th) and a little of English are included (20th). All data follow the same transcription guidelines as far as we know. Superscript is presented with a \^ before the characters. eg. Mme abbreviation is written M\^me in all the dataset we used. Sometime, `{$<>$}` would be used to mark strike-through. All data were produced in eScriptorium with segmentation from Kraken.},
  keywords = {kraken_pytorch},
  file = {/Users/kellychristensen/Zotero/storage/LW9KLGSW/6657809.html}
}

@inproceedings{chagueHTRUnitedMutualisonsVerite2021,
  title = {{{HTR-United}} : {{Mutualisons}} La Vérité de Terrain !},
  shorttitle = {{{HTR-United}}},
  booktitle = {{{DHNord2021}} - {{Publier}}, Partager, Réutiliser Les Données de La Recherche : Les Data Papers et Leurs Enjeux},
  author = {Chagué, Alix and Clérice, Thibault and Romary, Laurent},
  date = {2021-11},
  publisher = {{MESHS}},
  location = {{Lille, France}},
  url = {https://hal.archives-ouvertes.fr/hal-03398740},
  urldate = {2022-08-10},
  keywords = {Contrôle qualité,Datasets,Ground truth data,Handwritten Text Recognition,Jeu de données,Quality Evaluation,Reconnaissance automatique d'écriture manuscrite,Vérité de terrain},
  file = {/Users/kellychristensen/Zotero/storage/FERPIN7F/Chagué et al. - 2021 - HTR-United  Mutualisons la vérité de terrain !.pdf}
}

@software{chagueLECTAUREPContemporaryFrench2022,
  title = {{{LECTAUREP Contemporary French Model}} ({{Administration}})},
  author = {Chagué, Alix},
  date = {2022-05-12},
  url = {https://zenodo.org/record/6542744},
  urldate = {2022-08-12},
  abstract = {Description The model was trained from the ground truth produced by the LECTAUREP Project (Inria \& Archives Nationales) between 2019 and 2022. The training dataset contained many handwriting examples taken from French administrative documents produced between 1742 and 1928. Training and Testing datasets The data was collected from LECTAUREP's ground truth repositories: - lectaurep-bronod v0.0.1 - lectaurep-mariages-et-divorces v.1.0 - lectaurep-repertoires v2.0 12 pages were kept aside to create a test set. The training dataset contained: - 308 files - 19 364 lines - 329 270 characters The test dataset contained: - 12 files - 962 lines - 15 243 characters ~ Transcription standards The transcriptions were created with eScriptorium. They respect what is written (abbreviations are not developed, capitalization follows 19th century practices). Superscripted portions of text are signaled by `\^` and many signatures are transcription with ¥. Training The model was trained using the NFD normalization. Credits The model was trained by Alix Chagué using data created by Aurélia Rostaing, Françoise Limon-Bonnet, Nathalie Denis and Marc Durand. Additional information - more information on the LECTAUREP Project can be found at https://lectaurep.hypotheses.org/ - more information on the model can be found at https://github.com/lectaurep/lectaurep\_base\_model},
  organization = {{Zenodo}},
  keywords = {Contemporary French,French,HTR,kraken_pytorch,recognition model,transcription model},
  file = {/Users/kellychristensen/Zotero/storage/EJTTCQSH/6542744.html}
}

@inproceedings{chagueSharingHTRDatasets2022,
  title = {Sharing {{HTR}} Datasets with Standardized Metadata: The {{HTR-United}} Initiative},
  shorttitle = {Sharing {{HTR}} Datasets with Standardized Metadata},
  author = {Chagué, Alix and Clérice, Thibault},
  date = {2022-06-23},
  url = {https://hal.inria.fr/hal-03703989},
  urldate = {2022-08-12},
  eventtitle = {Documents Anciens et Reconnaissance Automatique Des Écritures Manuscrites},
  langid = {english},
  file = {/Users/kellychristensen/Zotero/storage/WE9LUH4A/Chagué and Clérice - 2022 - Sharing HTR datasets with standardized metadata t.pdf;/Users/kellychristensen/Zotero/storage/2MHWG278/hal-03703989.html}
}

@software{christensenGallicorporaApplication,
  title = {Gallicorpora/Application},
  author = {Christensen, Kelly},
  url = {https://github.com/Gallicorpora/application},
  urldate = {2022-08-21},
  file = {/Users/kellychristensen/Zotero/storage/MXUSAFLW/application.html}
}

@inproceedings{christensenGallicOrporTraitment2022,
  title = {Gallic(Orpor)a: {{Traitment}} Des Sources Textuelles En Diachronie Longue de {{Gallica}}},
  shorttitle = {Gallic(Orpor)a},
  booktitle = {{{DataLab}} de La {{BnF}}},
  author = {Christensen, Kelly and Pinche, Ariane and Gabay, Simon},
  date = {2022-06},
  location = {{Paris, France}},
  url = {https://hal.archives-ouvertes.fr/hal-03716534},
  urldate = {2022-08-09},
  file = {/Users/kellychristensen/Zotero/storage/4NVVI9G5/Christensen et al. - 2022 - Gallic(orpor)a Traitment des sources textuelles e.pdf}
}

@software{clericeDeucalionModeleAncien2019,
  title = {Deucalion, {{Modèle Ancien Francais}} (0.2.0)},
  author = {Clérice, Thibault and Camps, Jean-Baptiste and Pinche, Ariane},
  date = {2019-06-03},
  doi = {10.5281/zenodo.3237455},
  url = {https://zenodo.org/record/3237455},
  urldate = {2022-08-09},
  abstract = {No description provided.},
  organization = {{Zenodo}},
  file = {/Users/kellychristensen/Zotero/storage/KPLKJ8XU/3237455.html}
}

@software{clericeHTRVXHTRValidation2021,
  title = {{{HTRVX}}, {{HTR Validation}} with {{XSD}}},
  author = {Clérice, Thibault and Pinche, Ariane},
  date = {2021-09},
  doi = {10.5281/zenodo.5359963},
  url = {https://github.com/HTR-United/HTRVX},
  urldate = {2022-08-12},
  abstract = {HTRVX : HTR Validation with XSD},
  version = {0.0.1}
}

@dataset{clericeYALTAiSegmontoManuscript2022,
  title = {{{YALTAi}}: {{Segmonto Manuscript}} and {{Early Printed Book Dataset}}},
  shorttitle = {{{YALTAi}}},
  author = {Clérice, Thibault},
  date = {2022-07-10},
  publisher = {{Zenodo}},
  doi = {10.5281/zenodo.6814770},
  url = {https://zenodo.org/record/6814770},
  urldate = {2022-08-12},
  abstract = {This dataset has been built to train a segmentation model. It contains ALTO and YOLOv5 formats This dataset is derived from: CREMMA Medieval ( Pinche, A. (2022). Cremma Medieval (Version Bicerin 1.1.0) [Data set]. https://github.com/HTR-United/cremma-medieval ) CREMMA Medieval Lat (Clérice, T. and~Vlachou-Efstathiou, M. (2022). Cremma Medieval Latin [Data set]. https://github.com/HTR-United/cremma-medieval-lat ) Eutyches. (Vlachou-Efstathiou, M. Voss.Lat.O.41 - Eutyches "de uerbo" glossed [Data set]. https://github.com/malamatenia/Eutyches) Gallicorpora HTR-Incunable-15e-Siecle ( Pinche, A., Gabay, S., Leroy, N., \& Christensen, K. Données HTR incunable du 15e siècle [Computer software]. https://github.com/Gallicorpora/HTR-incunable-15e-siecle ) Gallicorpora HTR-MSS-15e-Siecle ( Pinche, A., Gabay, S., Leroy, N., \& Christensen, K. Données HTR manuscrits du 15e siècle [Computer software]. https://github.com/Gallicorpora/HTR-MSS-15e-Siecle ) Gallicorpora HTR-imprime-gothique-16e-siecle ( Pinche, A., Gabay, S., Vlachou-Efstathiou, M., \& Christensen, K. HTR-imprime-gothique-16e-siecle [Computer software]. https://github.com/Gallicorpora/HTR-imprime-gothique-16e-siecle ) + a few hundred newly annotated data, specifically the test set which is completely novel and based on early prints and manuscripts. ~ Dataset Number of images Train 854 Dev 154 Test 139},
  file = {/Users/kellychristensen/Zotero/storage/X264W5J6/6814770.html}
}

@inproceedings{coquenetHandwrittenTextRecognition2021,
  title = {Handwritten Text Recognition: From Isolated Text Lines to Whole Documents},
  shorttitle = {Handwritten Text Recognition},
  booktitle = {{{ORASIS}} 2021},
  author = {Coquenet, Denis and Chatelain, Clément and Paquet, Thierry},
  date = {2021-09},
  publisher = {{Centre National de la Recherche Scientifique [CNRS]}},
  location = {{Saint Ferréol, France}},
  url = {https://hal.archives-ouvertes.fr/hal-03339648},
  urldate = {2022-08-04},
  abstract = {The handwriting recognition task is largely dominated by deep neural networks. However, it remains challenging for these advanced computer vision systems. Recently, the models have become more sophisticated, moving from line-level recognition to paragraph-level and even page-level recognition. In this paper, we will study those advances and the constraints that come with them, mainly focusing on two models we proposed: the Simple Predict \& Align Network and the Vertical Attention Network. Both handle paragraph images, and we outperformed the state of the art on three datasets: RIMES, IAM and READ 2016},
  keywords = {Attention,FCN,Handwritten text recognition,Seq2seq model},
  file = {/Users/kellychristensen/Zotero/storage/XV3NP84W/hal-03339648.html}
}

@article{daherEtudeDynamiqueEcritures2011,
  title = {Étude de la dynamique des écritures médiévales : analyse et classification des formes écrites},
  shorttitle = {Étude de la dynamique des écritures médiévales},
  author = {Daher, Hani and Eglin, Véronique and Bres, Stéphane and Vincent, Nicole},
  date = {2011},
  journaltitle = {Gazette du livre médiéval},
  volume = {56},
  number = {1},
  pages = {21--41},
  publisher = {{Persée - Portail des revues scientifiques en SHS}},
  doi = {10.3406/galim.2011.1980},
  url = {https://www.persee.fr/doc/galim_0753-5015_2011_num_56_1_1980},
  urldate = {2022-08-01},
  langid = {fre},
  file = {/Users/kellychristensen/Zotero/storage/PAXA67M9/Daher et al. - 2011 - Étude de la dynamique des écritures médiévales  a.pdf;/Users/kellychristensen/Zotero/storage/7ABKGUV9/galim_0753-5015_2011_num_56_1_1980.html}
}

@software{DigiPalDigitalResource2011,
  title = {{{DigiPal}} : {{Digital Resource}} and {{Database}} of {{Palaeography}}, {{Manuscripts}} and {{Diplomatic}}.},
  shorttitle = {{{DigiPal}}},
  date = {2011-22},
  location = {{London}},
  url = {http://www.digipal.eu/}
}

@misc{gabayEditiones17thFrench2018,
  title = {E-Ditiones, 17th c. {{French}} Sources},
  author = {Gabay, Simon},
  date = {2018-11},
  publisher = {{DARIAH}},
  url = {https://hal.archives-ouvertes.fr/hal-02388415},
  urldate = {2022-08-10},
  keywords = {Bibliothèque numérique,Digital library,French literature – 17th century,Littérature française – 17e siècle},
  annotation = {Published: Workshop DARIAH-CH},
  file = {/Users/kellychristensen/Zotero/storage/7LX8GK56/Gabay - 2018 - E-ditiones, 17th c. French sources.pdf}
}

@inproceedings{gabayFreEMAlemBERT2022,
  title = {From {{FreEM}} to {{D}}'{{AlemBERT}}},
  booktitle = {Proceedings of the 13th {{Language Resources}} and {{Evaluation Conference}}},
  author = {Gabay, Simon and Ortiz Suarez, Pedro and Bartz, Alexandre and Chagué, Alix and Bawden, Rachel and Gambette, Philippe and Sagot, Benoît},
  date = {2022-06},
  publisher = {{European Language Resources Association}},
  location = {{Marseille, France}},
  url = {https://hal.inria.fr/hal-03596653},
  urldate = {2022-08-10},
  abstract = {Language models for historical states of language are becoming increasingly important to allow the optimal digitisation and analysis of old textual sources. Because these historical states are at the same time more complex to process and more scarce in the corpora available, specific efforts are necessary to train natural language processing (NLP) tools adapted to the data. In this paper, we present our efforts to develop NLP tools for Early Modern French (historical French from the 16th to the 18th centuries). We present the FreEMmax corpus of Early Modern French and D'AlemBERT, a RoBERTa-based language model trained on FreEMmax. We evaluate the usefulness of D'AlemBERT by fine-tuning it on a part-of-speech tagging task, outperforming previous work on the test set. Importantly, we find evidence for the transfer learning capacity of the language model, since its performance on lesser-resourced time periods appears to have been boosted by the more resourced ones. We release D'AlemBERT and the open-sourced subpart of the FreEMmax corpus.},
  keywords = {Corpus creation,Création de corpus,Digital humanities,Early Modern French,Français classique,Humanités Numériques,Language modelling,Langues peu dotées,Less-resourced languages,Modèle de langue neuronal,Modélisation linguistique,Neural language representation models,Partie du discours,POS tagging},
  file = {/Users/kellychristensen/Zotero/storage/HKFU8AXU/hal-03596653v1.html}
}

@software{gabayFreEMcorporaFreEMnormFreEM2022,
  title = {{{FreEM-corpora}}/{{FreEMnorm}}: {{FreEM}} Norm {{Parallel}} Corpus},
  shorttitle = {{{FreEM-corpora}}/{{FreEMnorm}}},
  author = {Gabay, Simon},
  date = {2022-01-17},
  doi = {10.5281/zenodo.5865428},
  url = {https://zenodo.org/record/5865428},
  urldate = {2022-08-11},
  abstract = {Parallel corpus for Early Modern French},
  organization = {{Zenodo}},
  file = {/Users/kellychristensen/Zotero/storage/Z9TPEL6Y/5865428.html}
}

@misc{gabayOCR17GroundTruth2020,
  title = {{{OCR17}}: {{Ground Truth}} and {{Models}} for 17th c. {{French Prints}} (and Hopefully More)},
  shorttitle = {{{OCR17}}},
  author = {Gabay, Simon and Clérice, Thibault and Reul, Christian},
  date = {2020-05},
  url = {https://hal.archives-ouvertes.fr/hal-02577236},
  urldate = {2022-08-12},
  keywords = {17th c French,Construction de corpus,Corpus building,Data paper,Donnees,OCR,Training data,XVIIème siècle},
  file = {/Users/kellychristensen/Zotero/storage/5JTIN8E2/Gabay et al. - 2020 - OCR17 Ground Truth and Models for 17th c. French .pdf}
}

@inproceedings{gabayProjetFREEMRessources2022,
  title = {Le Projet {{FREEM}} : Ressources, Outils et Enjeux Pour l'étude Du Français d'{{Ancien Régime}}},
  shorttitle = {Le Projet {{FREEM}}},
  booktitle = {{{TALN}} 2022 - {{Traitement Automatique}} Des {{Langues Naturelles}}},
  author = {Gabay, Simon and Ortiz Suarez, Pedro and Bawden, Rachel and Bartz, Alexandre and Gambette, Philippe and Sagot, Benoît},
  editor = {Estève, Yannick and Jiménez, Tania and Parcollet, Titouan and Zanon Boito, Marcely},
  date = {2022-06},
  pages = {154--165},
  publisher = {{ATALA}},
  location = {{Avignon, France}},
  url = {https://hal.archives-ouvertes.fr/hal-03701524},
  urldate = {2022-08-10},
  keywords = {Diachronic linguistics,linguistic normalisation,Linguistique diachronique,Named-entity recognition,Normalisation,Reconnaissance d'entités nommées},
  file = {/Users/kellychristensen/Zotero/storage/HR4YIFPV/Gabay et al. - 2022 - Le projet FREEM  ressources, outils et enjeux pou.pdf}
}

@inproceedings{gabaySegmOnto2021,
  title = {{{SegmOnto}}},
  booktitle = {Création de Modèle(s) {{HTR}} Pour Les Documents Médiévaux En Ancien Français et Moyen Français Entre Le {{Xe-XIVe}} Siècle},
  author = {Gabay, Simon and Camps, Jean-Baptiste and Pinche, Ariane},
  date = {2021-11},
  publisher = {{Ecole nationale des chartes | PSL}},
  location = {{Paris, France}},
  url = {https://hal.archives-ouvertes.fr/hal-03481089},
  urldate = {2022-07-25},
  keywords = {Controlled vocabularies,Handwritten Text Recognition,Manuscript,Manuscrits,Reconnaissance automatique d'écriture manuscrite,Vocabulaire contrôlé},
  file = {/Users/kellychristensen/Zotero/storage/EDZ8FJM7/hal-03481089.html}
}

@inproceedings{gabaySegmOntoCommonVocabulary2021,
  title = {{{SegmOnto}}: Common Vocabulary and Practices for Analysing the Layout of Manuscripts (and More)},
  shorttitle = {{{SegmOnto}}},
  booktitle = {1st {{International Workshop}} on {{Computational Paleography}} ({{IWCP}}@{{ICDAR}} 2021)},
  author = {Gabay, Simon and Camps, Jean-Baptiste and Pinche, Ariane and Jahan, Claire},
  date = {2021-09},
  location = {{Lausanne, Switzerland}},
  url = {https://hal.archives-ouvertes.fr/hal-03336528},
  urldate = {2022-08-09},
  keywords = {Analyse de disposition,controlled vocabulary,Imprimés modernes,layout analysis,manuscripts,Manuscrits,old prints,Vocabulaire controlé},
  file = {/Users/kellychristensen/Zotero/storage/5SL2XWCM/Gabay et al. - 2021 - SegmOnto common vocabulary and practices for anal.pdf}
}

@inproceedings{gabayStandardizingLinguisticData2020,
  title = {Standardizing Linguistic Data: Method and Tools for Annotating (Pre-Orthographic) {{French}}},
  shorttitle = {Standardizing Linguistic Data},
  booktitle = {Proceedings of the 2nd {{International Digital Tools}} \& {{Uses Congress}} ({{DTUC}} '20)},
  author = {Gabay, Simon and Clérice, Thibault and Camps, Jean-Baptiste and Tanguy, Jean-Baptiste and Gille-Levenson, Matthias},
  date = {2020-10},
  location = {{Hammamet, Tunisia}},
  doi = {10.1145/3423603.3423996},
  url = {https://hal.archives-ouvertes.fr/hal-03018381},
  urldate = {2022-08-12},
  abstract = {With the development of big corpora of various periods, it becomes crucial to standardise linguistic annotation (e.g. lemmas, POS tags, morphological annotation) to increase the interoperability of the data produced, despite diachronic variations. In the present paper, we describe both methodologically (by proposing annotation principles) and technically (by creating the required training data and the relevant models) the production of a linguistic tagger for (early) modern French (16-18th c.), taking as much as possible into account already existing standards for contemporary and, especially, medieval French.},
  keywords = {Etiquetage morpho-syntaxique,lemmatisation,Lemmatisation,linguistic annotation,POS-tagging,POStagging,pre-orthographic language},
  file = {/Users/kellychristensen/Zotero/storage/2ZQ6IGIU/Gabay et al. - 2020 - Standardizing linguistic data method and tools fo.pdf}
}

@book{gacekArabicManuscriptTradition2001,
  title = {The Arabic Manuscript Tradition : A Glossary of Technical Terms and Bibliography},
  author = {Gacek, Adam},
  date = {2001},
  series = {Handbook of {{Oriental Studies}}},
  number = {1, The Near and Middle East},
  publisher = {{Brill}},
  location = {{Leiden}},
  isbn = {ISBN 90-04-12061-0},
  pagetotal = {269}
}

@article{GlossaireCodicologiqueFrancaisarabe2002,
  title = {Glossaire codicologique français-arabe},
  date = {2002},
  journaltitle = {Gazette du livre médiéval},
  volume = {40},
  number = {1},
  pages = {79--80},
  publisher = {{Persée - Portail des revues scientifiques en SHS}},
  url = {https://www.persee.fr/doc/galim_0753-5015_2002_num_40_1_1563},
  urldate = {2022-07-25},
  langid = {fre},
  file = {/Users/kellychristensen/Zotero/storage/YT5ASFJM/galim_0753-5015_2002_num_40_1_1563.html}
}

@article{goodrichKurzweilReadingMachine1979,
  title = {Kurzweil {{Reading Machine}}: {{A Partial Evaluation}} of {{Its Optical Character Recognition Error Rate}}},
  shorttitle = {Kurzweil {{Reading Machine}}},
  author = {Goodrich, Gregory},
  date = {1979-01-12},
  journaltitle = {Journal of Visual Impairment and Blindness},
  shortjournal = {Journal of Visual Impairment and Blindness},
  abstract = {A study designed to assess the ability of the Kurzweil reading machine (a speech reading device for the visually handicapped) to read three different type styles produced by five different means indicated that the machines tested had different error rates depending upon the means of producing the copy and upon the type style used. (Author/CL)},
  file = {/Users/kellychristensen/Zotero/storage/JATPXPSA/Goodrich - 1979 - Kurzweil Reading Machine A Partial Evaluation of .pdf}
}

@article{govindanCharacterRecognitionReview1990,
  title = {Character Recognition — {{A}} Review},
  author = {Govindan, V. K. and Shivaprasad, A. P.},
  date = {1990},
  journaltitle = {Pattern Recognition},
  volume = {23},
  number = {7},
  pages = {671},
  issn = {0031-3203},
  url = {https://www.academia.edu/6986960/Character_recognition_A_review},
  urldate = {2022-08-05},
  abstract = {Character recognition - A review},
  langid = {english},
  file = {/Users/kellychristensen/Zotero/storage/ACCVNSEK/Govindan and Shivaprasad - 1990 - Character recognition — A review.pdf}
}

@inproceedings{guibonParsingPoorlyStandardized2014,
  title = {Parsing {{Poorly Standardized Language Dependency}} on {{Old French}}},
  booktitle = {Thirteenth {{International Workshop}} on {{Treebanks}} and {{Linguistic Theories}} ({{TLT13}})},
  author = {Guibon, Gaël and Tellier, Isabelle and Constant, Mathieu and Prévost, Sophie and Gerdes, Kim},
  editor = {Henrich, V. and Hinrichs, E. and de Kok, D. and Przepiórkowski, P. Osenova \& A.},
  date = {2014-12},
  series = {Proceedings of the {{Thirteenth International Workshop}} on {{Treebanks}} and {{Linguistic Theories}} ({{TLT13}})},
  pages = {51--61},
  location = {{Tübingen, Germany}},
  url = {https://hal.archives-ouvertes.fr/hal-01250959},
  urldate = {2022-08-10},
  abstract = {This paper presents results of dependency parsing of Old French, a language which is poorly standardized at the lexical level, and which displays a relatively free word order. The work is carried out on five distinct sample texts extracted from the dependency treebank Syntactic Reference Corpus of Medieval French (SRCMF). Following Achim Stein's previous work, we have trained the Mate parser on each sub-corpus and cross-validated the results. We show that the parsing efficiency is diminished by the greater lexical variation of Old French compared to parse results on modern French. In order to improve the result of the POS tagging step in the parsing process, we applied a pre-treatment to the data, comparing two distinct strategies: one using a slightly post-treated version of the TreeTagger trained on Old French by Stein, and a CRF trained on the texts, enriched with external resources. The CRF version outperforms every other approach.},
  keywords = {corpus exploration,dependency parsing,machine learning,Old French,POS labelling},
  file = {/Users/kellychristensen/Zotero/storage/PMSX9XAH/Guibon et al. - 2014 - Parsing Poorly Standardized Language Dependency on.pdf}
}

@online{HTRUnited,
  title = {{{HTR United}}},
  url = {https://github.com/HTR-United},
  urldate = {2022-08-12},
  file = {/Users/kellychristensen/Zotero/storage/RHB584K7/HTR-United.html}
}

@inproceedings{janesAutomaticTEIEncoding2021,
  title = {Towards Automatic {{TEI}} Encoding via Layout Analysis},
  booktitle = {Fantastic Future 21, 3rd {{International Conference}} on {{Artificial Intelligence}} for {{Librairies}}, {{Archives}} and {{Museums}}},
  author = {Janes, Juliette and Pinche, Ariane and Jahan, Claire and Gabay, Simon},
  date = {2021-12},
  publisher = {{AI for Libraries, Archives, and Museums (ai4lam)}},
  location = {{Paris, France}},
  url = {https://hal.archives-ouvertes.fr/hal-03527287},
  urldate = {2022-08-09},
  file = {/Users/kellychristensen/Zotero/storage/A5NMDGWE/Janes et al. - 2021 - Towards automatic TEI encoding via layout analysis.pdf}
}

@software{kiesslingKrakenOCRSystem2022,
  title = {The {{Kraken OCR}} System},
  author = {Kiessling, Benjamin},
  date = {2022-04},
  origdate = {2015-05-19T09:24:38Z},
  url = {https://kraken.re},
  urldate = {2022-08-02},
  abstract = {OCR engine for all the languages},
  version = {4.1.2}
}

@inproceedings{kiesslingKrakenUniversalText2019,
  title = {Kraken - an {{Universal Text Recognizer}} for the {{Humanities}}},
  author = {Kiessling, Benjamin},
  date = {2019},
  url = {https://dh-abstracts.library.cmu.edu/works/9912},
  urldate = {2022-08-10},
  eventtitle = {{{ADHO}} 2019 - {{Utrecht}}},
  langid = {english},
  file = {/Users/kellychristensen/Zotero/storage/RKJM3C3D/9912.html}
}

@article{lassnerPublishingOCRGround2021,
  title = {Publishing an {{OCR}} Ground Truth Data Set for Reuse in an Unclear Copyright Setting. {{Two}} Case Studies with Legal and Technical Solutions to Enable a Collective {{OCR}} Ground Truth Data Set Effort},
  author = {Lassner, David and Coburger, Julius and Neudecker, Clemens and Baillot, Anne},
  date = {2021},
  journaltitle = {Fabrikation von Erkenntnis – Experimente in den Digital Humanities. Hg. von Manuel Burghardt},
  volume = {Lisa Dieckmann},
  pages = {5)},
  publisher = {{Zeitschrift für digitale Geisteswissenschaften - ZfdG}},
  doi = {10.17175/SB005_006},
  url = {https://zfdg.de/sb005_006},
  urldate = {2022-08-10},
  abstract = {We present an OCR ground truth data set for historical prints and show improvement of recognition results over baselines with training on this data. We reflect on reusability of the ground truth data set based on two experiments that look into the legal basis for reuse of digitized document images in the case of 19th century English and German books. We propose a framework for publishing ground truth data even when digitized document images cannot be easily redistributed.},
  editora = {Herzog August Bibliothek},
  editoratype = {collaborator},
  langid = {english},
  version = {1.0},
  file = {/Users/kellychristensen/Zotero/storage/SGUYBJGG/Lassner et al. - 2021 - Publishing an OCR ground truth data set for reuse .pdf}
}

@book{maniaciTerminologiaLibroManoscritto1996,
  title = {Terminologia Des Libro Manoscritto},
  author = {Maniaci, Marilena},
  date = {1996},
  series = {Addenda},
  number = {3},
  publisher = {{Istituto centrale per la patologia del libro}},
  location = {{Rome}}
}

@inproceedings{martinCamemBERTTastyFrench2020,
  title = {{{CamemBERT}}: A {{Tasty French Language Model}}},
  shorttitle = {{{CamemBERT}}},
  booktitle = {Proceedings of the 58th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Martin, Louis and Muller, Benjamin and Ortiz Suárez, Pedro Javier and Dupont, Yoann and Romary, Laurent and de la Clergerie, Éric and Seddah, Djamé and Sagot, Benoît},
  options = {useprefix=true},
  date = {2020-07},
  pages = {7203--7219},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2020.acl-main.645},
  url = {https://aclanthology.org/2020.acl-main.645},
  urldate = {2022-08-11},
  abstract = {Pretrained language models are now ubiquitous in Natural Language Processing. Despite their success, most available models have either been trained on English data or on the concatenation of data in multiple languages. This makes practical use of such models –in all languages except English– very limited. In this paper, we investigate the feasibility of training monolingual Transformer-based language models for other languages, taking French as an example and evaluating our language models on part-of-speech tagging, dependency parsing, named entity recognition and natural language inference tasks. We show that the use of web crawled data is preferable to the use of Wikipedia data. More surprisingly, we show that a relatively small web crawled dataset (4GB) leads to results that are as good as those obtained using larger datasets (130+GB). Our best performing model CamemBERT reaches or improves the state of the art in all four downstream tasks.},
  eventtitle = {{{ACL}} 2020},
  file = {/Users/kellychristensen/Zotero/storage/KBTVEMGY/Martin et al. - 2020 - CamemBERT a Tasty French Language Model.pdf}
}

@article{muehlbergerTransformingScholarshipArchives2019,
  title = {Transforming Scholarship in the Archives through Handwritten Text Recognition: {{Transkribus}} as a Case Study},
  shorttitle = {Transforming Scholarship in the Archives through Handwritten Text Recognition},
  author = {Muehlberger, Guenter and Seaward, Louise and Terras, Melissa and Ares Oliveira, Sofia and Bosch, Vicente and Bryan, Maximilian and Colutto, Sebastian and Déjean, Hervé and Diem, Markus and Fiel, Stefan and Gatos, Basilis and Greinoecker, Albert and Grüning, Tobias and Hackl, Guenter and Haukkovaara, Vili and Heyer, Gerhard and Hirvonen, Lauri and Hodel, Tobias and Jokinen, Matti and Kahle, Philip and Kallio, Mario and Kaplan, Frederic and Kleber, Florian and Labahn, Roger and Lang, Eva Maria and Laube, Sören and Leifert, Gundram and Louloudis, Georgios and McNicholl, Rory and Meunier, Jean-Luc and Michael, Johannes and Mühlbauer, Elena and Philipp, Nathanael and Pratikakis, Ioannis and Puigcerver Pérez, Joan and Putz, Hannelore and Retsinas, George and Romero, Verónica and Sablatnig, Robert and Sánchez, Joan Andreu and Schofield, Philip and Sfikas, Giorgos and Sieber, Christian and Stamatopoulos, Nikolaos and Strauß, Tobias and Terbul, Tamara and Toselli, Alejandro Héctor and Ulreich, Berthold and Villegas, Mauricio and Vidal, Enrique and Walcher, Johanna and Weidemann, Max and Wurster, Herbert and Zagoris, Konstantinos},
  date = {2019-09-09},
  journaltitle = {Journal of Documentation},
  shortjournal = {JD},
  volume = {75},
  number = {5},
  pages = {954--976},
  issn = {0022-0418},
  doi = {10.1108/JD-07-2018-0114},
  url = {https://www.emerald.com/insight/content/doi/10.1108/JD-07-2018-0114/full/html},
  urldate = {2022-08-04},
  abstract = {Purpose – An overview of the current use of handwritten text recognition (HTR) on archival manuscript material, as provided by the EU H2020 funded Transkribus platform. It explains HTR, demonstrates Transkribus, gives examples of use cases, highlights the affect HTR may have on scholarship, and evidences this turning point of the advanced use of digitised heritage content. The paper aims to discuss these issues.},
  langid = {english},
  file = {/Users/kellychristensen/Zotero/storage/8UK6P99F/Muehlberger et al. - 2019 - Transforming scholarship in the archives through h.pdf}
}

@inreference{muzerelleCaviarder2011,
  title = {Caviarder},
  booktitle = {Codicologia},
  author = {Muzerelle, Denis},
  date = {2011},
  publisher = {{Institut de recherche et d'histoire des textes}},
  url = {http://codicologia.irht.cnrs.fr/theme/liste_theme/413#tr-868},
  urldate = {2022-07-25}
}

@book{muzerelleVocabulaireCodicologiqueRepertoire1985,
  title = {Vocabulaire Codicologique : Répertoire Méthodique Des Termes Français Relatifs Aux Manuscrits},
  author = {Muzerelle, Dennis},
  date = {1985},
  series = {Rubricae},
  number = {1},
  publisher = {{Éd. Cemi}},
  location = {{Paris}}
}

@software{NumpyNumPyFundamental,
  title = {Numpy: {{NumPy}} Is the Fundamental Package for Array Computing with {{Python}}.},
  shorttitle = {Numpy},
  url = {https://www.numpy.org},
  urldate = {2022-08-04},
  version = {1.23.1},
  keywords = {Scientific/Engineering,Software Development},
  file = {/Users/kellychristensen/Zotero/storage/QF4T3US4/numpy.html}
}

@book{ostosVocabularioCodicologIaVersion1997,
  title = {Vocabulario de {{codicologÍa}} : Versión Española Revisada y Aumentada Del Vocabulaire Codicologique},
  author = {Ostos, Pilar and Pardo, M. Luisa and Rodríguez, Elena E.},
  date = {1997},
  series = {Instrumenta Bibliologica},
  publisher = {{Arco/Libros}},
  location = {{Madrid}}
}

@article{otsuThresholdSelectionMethod1979,
  title = {A {{Threshold Selection Method}} from {{Gray-Level Histograms}}},
  author = {Otsu, Nobuyuki},
  date = {1979-01},
  journaltitle = {IEEE Transactions on Systems, Man, and Cybernetics},
  volume = {9},
  number = {1},
  pages = {62--66},
  abstract = {A nonparametric and unsupervised method of automatic threshold selection for picture segmentation is presented. An optimal threshold is selected by the discriminant criterion, namely, so as to maximize the separability of the resultant classes in gray levels. The procedure is very simple, utilizing only the zeroth- and the first-order cumulative moments of the gray-level histogram. It is t straightforward to extend the method to multithreshold problems.},
  langid = {english},
  file = {/Users/kellychristensen/Zotero/storage/HWBYE3C8/Otsu - A Tlreshold Selection Method from Gray-Level Histo.pdf}
}

@inproceedings{pincheCremmaLabProjectTranscription2022,
  title = {{{CremmaLab}} Project: {{Transcription}} Guidelines and {{HTR}} Models for {{French}} Medieval Manuscripts},
  shorttitle = {{{CremmaLab}} Project},
  booktitle = {Colloque ”{{Documents}} Anciens et Reconnaissance Automatique Des Écritures Manuscrites”},
  author = {Pinche, Ariane and Camps, Jean-Baptiste},
  date = {2022-06},
  location = {{Paris, France}},
  url = {https://hal.archives-ouvertes.fr/hal-03716526},
  urldate = {2022-08-10},
  file = {/Users/kellychristensen/Zotero/storage/QZUTS62T/hal-03716526.html}
}

@article{pincheHTRModelCremma2022,
  title = {HTR model Cremma Medieval},
  author = {Pinche, Ariane},
  date = {2022-06-21},
  publisher = {{Zenodo}},
  doi = {10.5281/zenodo.6669508},
  url = {https://zenodo.org/record/6669508},
  urldate = {2022-08-10},
  abstract = {This project was funded by the DIM MAP in the context of the CREMMA project (https://www.dim-map.fr/projets-soutenus/cremma/) The cremma-medieval repository was created in order to make available transcription corpora for training HTR models for medieval manuscripts from the 12th to the 14th century. The CREMMA Medieval dataset has been built with eScriptorium (http://traces6.paris.inria.fr), an interface for HTR ground truth production, and, an HTR and layout segmentation engine. It is composed of ten Old French manuscripts written between the 13th and 14th centuries, mainly scanned in high definition and color except for one manuscript (Vatican) which is a black and white document and BnF fr. 17229, 13496 and 411 that come from microfilm scans. The datasets is mostly made from pre-existing transcribed texts and the samples size can be very different from one source manuscript to the other. The basis of the dataset is composed of the following transcriptions : Bibliothèqe nationale de France, Arsenal 3516, Crowdsourced transcriptions of the collaborative projects of the Standford Library: Bestiaire de Guillaume le Clerc de Normandie (https://fromthepage.com/stanfordlibraries/guillaume-le-clerc-de-normandie-s-bestiary) Bibliothèqe nationale de France, fr.~411,~Vie de saint Lambert~transcribed by A. Pinche (ENC) Bibliothèqe nationale de France, fr.~412,~Li Seint Confessor~de Wauchier de Denain transcribed by A. Pinche (ENC) Bibliothèqe nationale de France, fr.~844,~Manuscrit du Roi, Maritem project(https://anr.fr/Projet-ANR-18-CE27-0016) transcribed by V. Mariotti (projet Maritem) Bibliothèqe nationale de France, fr.~13496,~Vie de saint Jérôme~transcribed by A. Pinche (ENC) Bibliothèqe nationale de France, fr.~17229,~Vie de saint Jérôme~transcribed by A. Pinche (ENC) Bibliothèqe nationale de France, fr.~25516,~Beuve de Hantone~transcribed By A. Nolibois (Université d'Aix-Marseille) Bibliothèqe nationale de France, fr.22550,~Les Sept Sages de Thèbes, this project just started in Geneva under the direction of Y. Foehr-Janssen (UNIGE), the different have been transcribed by Camille Carnaille (ULB/UNIGE) (fol.157r, 163v, 174v, 178v, 186v, 200v), Prunelle Deleville (UNIGE) (fol. 157v, 178r, 186r, 200r, 204r, 343v), Sophie Lecomte (ULB) (fol. 174v), Aminoel Meylan (UNIGE) (169r), Simone Ventura (ULB) (fol. 163r). Cologny, Bodmer, 168 and Vatican, Reg. Lat., 1616,~Chanson d'Otinel~transcribed by J.~-B.~Camps (ENC) from the Geste project (https://github.com/Jean-Baptiste-Camps/Geste) University of pennsylvania, codex 660, pelerinage de mademoiselle Sapience, transcribe by Ariane Pinche (ENC) University of pennsylvania, codex 909,~Énéide, transcribed by Lucien Dugaz (ENC) As the data come from different projects, transcriptions have been standardized to strengthen HTR models. We chose a graphemic transcription method, following D. Stutzmann definitions (see bibliography), to have a sign in the image corresponding to a sign in our text: all the abbreviations are kept, and u/v or i/j are not distinguished. The spaces in the dataset are not homogeneously represented, sometimes transcriptions reproduce the manuscript spacing while others use lexical spaces. It must be stressed that spaces are the most important source of error in medieval HTR models. Most of the transcription follow the layout segmentation of the SegmOnto ontology (https://github.com/SegmOnto/examples), separating the main column, margin, numbering, drop capital, etc. To ensure the quality of the data, continuous integration workflow (Github Actions) has been put in place checking the segmentation vocabulary : SegmentoKraken, XML schema validator (segmentoAltoValidator.xsd), but also the homogeneity of the signs of the characters used in the dataset through a list of authorized signs and translation table (table.csv) with ChocoMufin.},
  langid = {fro},
  keywords = {kraken_pytorch},
  file = {/Users/kellychristensen/Zotero/storage/S8JWSABY/6669508.html}
}

@software{pincheHTRUnitedCremmamedievalCortado2022,
  title = {{{HTR-United}}/Cremma-Medieval: {{Cortado}} 2.0.0},
  shorttitle = {{{HTR-United}}/Cremma-Medieval},
  author = {Pinche, Ariane and Clérice, Thibault},
  date = {2022-07-11},
  doi = {10.5281/zenodo.6818057},
  url = {https://zenodo.org/record/6818057},
  urldate = {2022-08-12},
  abstract = {Model mixing cremma-medieval dataset with early prints (15e s.) from Gallic(orpor)a project. Test score (Based on CER) : 95,54 \%},
  organization = {{Zenodo}},
  file = {/Users/kellychristensen/Zotero/storage/F9NJ4N4K/6818057.html}
}

@inproceedings{regnaultChallengesLanguageChange2019,
  title = {Challenges of Language Change and Variation: Towards an Extended Treebank of {{Medieval French}}},
  shorttitle = {Challenges of Language Change and Variation},
  booktitle = {{{TLT}} 2019 - 18th {{International Workshop}} on {{Treebanks}} and {{Linguistic Theories}}},
  author = {Regnault, Mathilde and Prévost, Sophie and Villemonte de La Clergerie, Éric},
  date = {2019-08},
  location = {{Paris, France}},
  url = {https://hal.inria.fr/hal-02272560},
  urldate = {2022-08-10},
  abstract = {In order to automatically extend a treebank of Old French (9 th-13 th c.) with new texts in Old and Middle French (14 th-15 th c.), we need to adapt tools for syntactic annotation. However, these stages of French are subjected to great variation, and parsing historical texts remains an issue. We chose to adapt a symbolic system, the French Metagrammar (FRMG), and develop a lexicon comparable to the Lefff lexicon for Old and Middle French. The final goal of our project is to model the evolution of language through the whole period of Medieval French (9 th-15 th c.).},
  file = {/Users/kellychristensen/Zotero/storage/4CT4GTK9/Regnault et al. - 2019 - Challenges of language change and variation towar.pdf}
}

@inproceedings{sagotLefffFreelyAvailable2010,
  title = {The {{Lefff}}, a Freely Available and Large-Coverage Morphological and Syntactic Lexicon for {{French}}},
  booktitle = {7th International Conference on {{Language Resources}} and {{Evaluation}} ({{LREC}} 2010)},
  author = {Sagot, Benoît},
  date = {2010-05},
  location = {{Valletta, Malta}},
  url = {https://hal.inria.fr/inria-00521242},
  urldate = {2022-08-10},
  abstract = {In this paper, we introduce the Lefff , a freely available, accurate and large-coverage morphological and syntactic lexicon for French, used in many NLP tools such as large-coverage parsers. We first describe Alexina, the lexical framework in which the Lefff is developed as well as the linguistic notions and formalisms it is based on. Next, we describe the various sources of lexical data we used for building the Lefff , in particular semi-automatic lexical development techniques and conversion and merging of existing resources. Finally, we illustrate the coverage and precision of the resource by comparing it with other resources and by assessing its impact in various NLP tools.},
  file = {/Users/kellychristensen/Zotero/storage/YXDDAEND/Sagot - 2010 - The Lefff, a freely available and large-coverage m.pdf}
}

@article{schneiderProductionMachinereadableText1971,
  title = {The Production of Machine-Readable Text: {{Some}} of the Variables},
  shorttitle = {The Production of Machine-Readable Text},
  author = {Schneider, Ben R.},
  date = {1971-09},
  journaltitle = {Computers and the Humanities},
  shortjournal = {Comput Hum},
  volume = {6},
  number = {1},
  pages = {39--47},
  issn = {0010-4817, 1572-8412},
  doi = {10.1007/BF02402324},
  url = {http://link.springer.com/10.1007/BF02402324},
  urldate = {2022-08-02},
  langid = {english},
  file = {/Users/kellychristensen/Zotero/storage/D33T3DJE/Schneider - 1971 - The production of machine-readable text Some of t.pdf}
}

@article{siddiqiWritingPropertyDescriptors2011,
  title = {Writing Property Descriptors : A Proposal for Typological Groupings},
  shorttitle = {Writing Property Descriptors},
  author = {Siddiqi, Imran-Ahmed and Cloppet, Florence and Vincent, Nicole},
  date = {2011},
  journaltitle = {Gazette du livre médiéval},
  volume = {56},
  number = {1},
  pages = {42--57},
  publisher = {{Persée - Portail des revues scientifiques en SHS}},
  doi = {10.3406/galim.2011.1981},
  url = {https://www.persee.fr/doc/galim_0753-5015_2011_num_56_1_1981},
  urldate = {2022-08-02},
  langid = {english},
  file = {/Users/kellychristensen/Zotero/storage/BKK73FAN/galim_0753-5015_2011_num_56_1_1981.html}
}

@inproceedings{steinOldFrenchDependency2016,
  title = {Old {{French}} Dependency Parsing : {{Results}} of Two Parsers Analysed from a Linguistic Point of View},
  author = {Stein, Achim},
  date = {2016},
  pages = {707--713},
  publisher = {{European Language Resources Association (ELRA)}},
  location = {{Portorož, Slovenia}},
  abstract = {The treatment of medieval texts is a particular challenge for parsers. I compare how two dependency parsers, one graph-based, the other transition-based, perform on Old French, facing some typical problems of medieval texts: graphical variation, relatively free word order, and syntactic variation of several parameters over a diachronic period of about 300 years. Both parsers were trained and evaluated on the Syntactic Reference Corpus of Medieval French (SRCMF), a manually annotated dependency treebank. I discuss the relation between types of parsers and types of language, as well as the differences of the analyses from a linguistic point of view.},
  eventtitle = {Proceedings of the {{Tenth International Conference}} on {{Language Resources}} an  {{Evaluation}} ({{LREC}}’16)},
  langid = {english},
  file = {/Users/kellychristensen/Zotero/storage/D9KPCB8P/Stein - Old French Dependency Parsing Results of Two Pars.pdf}
}

@book{steinSyntacticAnnotationMedieval2013,
  title = {Syntactic Annotation of Medieval Texts: The {{Syntactic Reference Corpus}} of {{Medieval French}} ({{SRCMF}})},
  shorttitle = {Syntactic Annotation of Medieval Texts},
  author = {Stein, Achim and Prévost, Sophie},
  date = {2013},
  pages = {275},
  publisher = {{Narr Verlag}},
  url = {https://halshs.archives-ouvertes.fr/halshs-01122079},
  urldate = {2022-08-10},
  abstract = {This article presents the Syntactic Reference Corpus of Medieval French (SRCMF).},
  isbn = {978-3-8233-6760-4},
  langid = {english},
  file = {/Users/kellychristensen/Zotero/storage/HT4KY8MQ/Stein and Prévost - 2013 - Syntactic annotation of medieval texts the Syntac.pdf;/Users/kellychristensen/Zotero/storage/FDL2LFIZ/halshs-01122079.html}
}

@book{steinSyntacticReferenceCorpus2013,
  title = {Syntactic {{Reference Corpus}} of {{Medieval French}} ({{SRCMF}})},
  author = {Stein, Achim and Prévost, Sophie},
  date = {2013},
  publisher = {{ILR University of Stuttgart}},
  location = {{Stuttgart}},
  url = {http://srcmf.org},
  isbn = {899-492-963-833-3}
}

@online{TeamSegmOntoDocumentation,
  title = {The Team - {{SegmOnto Documentation}}},
  url = {https://segmonto.github.io/pj/team/},
  urldate = {2022-07-25},
  file = {/Users/kellychristensen/Zotero/storage/2RNV576E/team.html}
}

@article{turingComputingMachineryIntelligence1950,
  title = {Computing {{Machinery}} and {{Intelligence}}},
  author = {Turing, A. M.},
  date = {1950-10-01},
  journaltitle = {Mind},
  shortjournal = {Mind},
  volume = {LIX},
  number = {236},
  pages = {433--460},
  issn = {0026-4423},
  doi = {10.1093/mind/LIX.236.433},
  url = {https://doi.org/10.1093/mind/LIX.236.433},
  urldate = {2022-08-04},
  file = {/Users/kellychristensen/Zotero/storage/A3JAIIG2/TURING - 1950 - I.—COMPUTING MACHINERY AND INTELLIGENCE.pdf;/Users/kellychristensen/Zotero/storage/ADX28XD4/986238.html}
}

@article{zarriQuelquesAspectsTechniques1977,
  title = {Quelques aspects techniques de l'exploitation informatique des documents textuels : saisie des données et problèmes de sortie},
  shorttitle = {Quelques aspects techniques de l'exploitation informatique des documents textuels},
  author = {Zarri, Gian Piero},
  date = {1977},
  journaltitle = {Publications de l'École Française de Rome},
  volume = {31},
  number = {1},
  pages = {399--413},
  publisher = {{Persée - Portail des revues scientifiques en SHS}},
  url = {https://www.persee.fr/doc/efr_0000-0000_1977_act_31_1_2286},
  urldate = {2022-08-01},
  langid = {fre},
  file = {/Users/kellychristensen/Zotero/storage/9PP8TLPN/Zarri - 1977 - Quelques aspects techniques de l'exploitation info.pdf;/Users/kellychristensen/Zotero/storage/67VGIS5R/efr_0000-0000_1977_act_31_1_2286.html}
}


