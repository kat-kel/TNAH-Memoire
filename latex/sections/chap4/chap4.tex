% PREAMBULE

% !BIB TS-program = biber
% !TEX TS-program = xelatexmk
% ITEX TS-program = latex

% !TEX spellcheck = French

\documentclass[class=article, crop=false]{standalone}
\usepackage[subpreambles=true]{standalone}
\usepackage{import}
\usepackage{blindtext}
\usepackage{fontspec}
\usepackage[french]{babel}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{csquotes}
\usepackage{url}

%%%%%%%%%%%%%%%%%%%%%%%%
%			DIAGRAM
\usepackage{tikz}
\usetikzlibrary{positioning}
\usetikzlibrary{calc, matrix, shapes.geometric, arrows}
\usepackage{pgfplots}
\usepackage{array}
\usepackage{tabularx}


%Example of code
\usepackage{listings}
\usepackage{color}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{cyan}{rgb}{0.0,0.6,0.6}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinelanguage{XML}{
  backgroundcolor=\color{backcolour},  
  basicstyle=\ttfamily\footnotesize,
  morestring=[s]{"}{"},
  moredelim=[s][\color{black}]{>}{<},
  morecomment=[s]{!--}{--},
  commentstyle=\color{codegreen},
  moredelim=[s][\color{red}]{\ }{=},
  stringstyle=\color{blue},
  identifierstyle=\color{cyan},
  numberstyle=\tiny\color{codegray},
  breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

%Code listing style named "json"
\lstdefinestyle{json}{
  backgroundcolor=\color{backcolour}, 
  basicstyle=\ttfamily\footnotesize,
  commentstyle=\color{codegreen},
  numberstyle=\tiny\color{codegray},
  basicstyle=\ttfamily\footnotesize,
  breakatwhitespace=false,         
  breaklines=true,                 
  captionpos=b,                    
  keepspaces=true,                 
  numbers=left,                    
  numbersep=5pt,                  
  showspaces=false,                
  showstringspaces=false,
  showtabs=false,                  
  tabsize=2
}


%%%%%%%%%%%%%%%%%%%%%%%%
%			REFERENCES
% le package hyperref avec des options, si en local
\usepackage[pdfusetitle, pdfsubject ={Mémoire TNAH}, pdfkeywords={les mots-clés}]{hyperref}
\usepackage[backend=bibtex, sorting=nyt, style=verbose-ibid]{biblatex}
\addbibresource{../../../bib.bib}

%%%%%%%%%%%%%%%%%%%%%%%%
%			GLOSSAIRE
\usepackage[acronym]{glossaries}
\makeglossaries
\newglossaryentry{htr}
{
    name=Handwritten Text Recognition,
    description={La reconnaissance du texte écrit sur une image numérique}
}
\newacronym{HTR}{HTR}{Handwritten Text Recognition}

\newglossaryentry{ocr}
{
    name=Optical Character Recognition,
    description={La reconnaissance des polices du texte sur une image numérique}
}
\newacronym{OCR}{OCR}{Optical Character Recognition}

\newglossaryentry{Inria}
{
    name=Inria,
    description={Institut national de recherche en sciences et technologies du numérique}
}
\newacronym{INRIA}{Inria}{Institut national de recherche en sciences et technologies du numérique}

\newacronym{almanach}{ALMAnaCH}{Automatic Language Modelling and Analysis \& Computational Humanities}

\newglossaryentry{enc}
{
    name=École nationale des chartes,
    description={Grande école bla bla bla}
}
\newacronym{ENC}{ENC}{École nationale des chartes}

\newglossaryentry{HTR-United}
{
    name=HTR-United,
    description={HTR-United is a catalog and an ecosystem for sharing and finding ground truth for optical character or handwritten text recognition (OCR/HTR)}
}

\newglossaryentry{CLab}
{
	name=CREMMALab,
	description={Consortium pour la reconnaissance
d’'écriture manuscrite des matériaux anciens}
}
\newacronym{CREMMA}{CREMMA}{Consortium Reconnaissance
d’Écriture Manuscrite des Matériaux Anciens}

\newglossaryentry{tei}
{
	name={Text Encoding Initiative},
	description={Normes internationales de l'encodage des documents texts}
}
\newacronym{TEI}{TEI}{Text Encoding Initiative}

\newglossaryentry{iiif}
{
	name={International Image Interoperability Framework},
	description={Normes internationales de l'exploitation des images numériques et de leurs métadonnées par API}
}
\newacronym{IIIF}{IIIF}{International Image Interoperability Framework}

\newacronym{ALTO}{ALTO}{Analyzed Layout and Text Object}

\newacronym{XML}{XML}{eXtensible Markup Language}

\newacronym{BNF}{BnF}{Bibliothèque nationale de France}

\newacronym{RDF}{RDF}{Resource Description Framework}

\newacronym{TAL}{TAL}{Traitement automatique des langues}

\newacronym{ARK}{ARK}{Archival Resource Key}

\newacronym{API}{API}{Application Programming Interface}

\newacronym{DTS}{DTS}{Distributed Text Services}

\newglossaryentry{iiifapi}
{
	name={IIIF Image API},
	description={Un service web qui renvoie une image suite à une requête standardisée HTTP(S). L'URI peut préciser la région, la taille, la rotation, la qualité, les caractéristiques, et le format de l'image demandée.}
}

\newglossaryentry{odd}
{
	name={One Document Does it all},
	description={Un fichier XML TEI qui précise les règles d'un schéma TEI personnalisé.}
}
\newacronym{ODD}{ODD}{One Document Does it all}

\newacronym{JSON}{JSON}{JavaScript Object Notation}

\newacronym{HTML}{HTML}{HyperText Markup Language}

%%%%%%%%%%%%%%%%%%%%%%%%
%			DOCUMENT
\begin{document}

Le pipeline du projet \textit{Gallic(orpor)a} se déroule dans cinq étapes. Dans un premier temps, il récupère les fac-similés numériques des documents sources sur Gallica. Dans un deuxième temps, il applique des modèles \acrshort{HTR} aux fac-similés ainsi téléchargés afin de produire une prédiction du texte et une transcription de la mise en page. Ensuite, il crée un fichier \acrshort{TEI} préliminaire qui réunit les données produites par les modèles \acrshort{HTR} et les métadonnées récupérées de plusieurs sources en ligne. Le quatrième étape enrichit le fichier \acrshort{TEI} avec une analyse linguistique du texte de la transcription. Et enfin, le pipeline export les données du fichier \acrshort{TEI} en divers formats, y compris les données conformant aux schémas \acrshort{RDF}, \acrshort{DTS}, et \acrshort{IIIF}.

\section{La récupération des fac-similés numériques}
L'accès aux pages numérisées d'un document source est une condition essentielle à toute étape du pipeline de \textit{Gallic(orpor)a}. Afin de transcrire le document source, il faut d'abord dire au logiciel comment il peut accéder au fac-similé numérique de la source. De plus, les images doivent être d'une qualité aussi bonne, sans être pourries par trop de bruit, que le logiciel \acrshort{HTR} peut bien reconnaître le texte et les segments dedans. Pour terminer, bien qu'il ne soit pas essentiel à la transcription des pages numérisées, les images devraient s'associer aux métadonnées qui portent sur le document source. Grâce à une telle relation entre source numérique et source physique, le pipeline enrichit la ressource numérique qu'elle livre avec les informations portant sur le document source.

\subsection{\acrlong{ARK} (\acrshort{ARK})}
\label{structure-fichier}
D'abord, avant de penser à récupérer les images, il faut mettre en place un système pour associer des pages, c'est-à-dire une suite d'images numériques, au document source, c'est-à-dire le concept d'une œuvre qui n'existe pas vraiment dans aucun format informatique. Pour associer plusieurs pages distinctes à un document, le pipeline profite d'un identifiant unique qui s'appelle l'\textit{\acrlong{ARK}} (\acrshort{ARK}). Très utilisé dans le monde archivistique, cette clef indique une ressource, soit numérique soit physique, dont la conservation une institution, telle que la \acrlong{BNF}, se charge. Le schéma \acrshort{ARK} est actuellement maintenu par la communauté ARK Alliance\footcite{allianceCommunity2020}. L'identifiant facilite la localisation d'une ressource, sans la confondre avec d'autres exemplaires de la même œuvre. La précision qu'accorde l'\acrshort{ARK} améliore l'exactitude d'un processus de traitement automatique.

\subsubsection{La mise en place d'un système de fichiers}
Le pipeline se sert de l'identifiant \acrshort{ARK} afin de gérer le lien entre les images numériques et le document source. La Figure~\ref{fig:filestructure} montre comment le système de fichiers du pipeline organise deux documents sources, où chacun a trois pages numérisées en format JPEG. Le chemin d'accès à chaque image se compose donc de l'identifiant \acrshort{ARK}. Ainsi son association au document source est conservée et accessible au logiciel. Par exemple, le chemin de fichier du deuxième folio du premier document montré dans la Figure~\ref{fig:filestructure} est \texttt{data/ARK1/folio2.jpg}. En portant un tel chemin, l'image est toujours associé au bon document.

\tikzstyle{folder} = [rectangle, rounded corners, minimum width=2cm, minimum height=0.75cm,text centered, draw=black, fill=yellow!30]
\tikzstyle{file} = [rectangle, rounded corners, minimum width=2cm, minimum height=0.75cm,text centered, draw=black, fill=gray!30]
\tikzstyle{arrow} = [thick,>=stealth]

\begin{figure}[htp]
\centering
\begin{tikzpicture}[node distance=0.5cm]

\node (data) [folder] {\texttt{data/}};

\node (ark1) [folder, below left = of data] {\footnotesize{\texttt{ARK1/}}};
\node (ark1img1) [file, below = of ark1] {\footnotesize{\texttt{folio1.jpg}}};
\node (ark1img2) [file, below = of ark1img1] {\footnotesize{\texttt{folio2.jpg}}};
\node (ark1img3) [file, below = of ark1img2] {\footnotesize{\texttt{folio3.jpg}}};

\node (ark2) [folder, below right = of data] {\footnotesize{\texttt{ARK2/}}};
\node (ark2img1) [file, below = of ark2] {\footnotesize{\texttt{folio1.jpg}}};
\node (ark2img2) [file, below = of ark2img1] {\footnotesize{\texttt{folio2.jpg}}};
\node (ark2img3) [file, below = of ark2img2] {\footnotesize{\texttt{folio3.jpg}}};

\draw [arrow] (data) -- (ark1);
\draw [arrow] (data) -- (ark2);
\draw[arrow] (ark1) -- (ark1img1);
\draw[arrow] (ark1img1) -- (ark1img2);
\draw[arrow] (ark1img2) -- (ark1img3);
\draw[arrow] (ark2) -- (ark2img1);
\draw[arrow] (ark2img1) -- (ark2img2);
\draw[arrow] (ark2img2) -- (ark2img3);
\end{tikzpicture}
\caption{Système de fichiers}
\label{fig:filestructure}
\end{figure}

\subsection{\acrlong{IIIF} (\acrshort{IIIF})}
En plus d'associer les images à leur document source, l'identifiant \acrshort{ARK} sert aussi à récupérer les images depuis l'internet. Ce genre de requête se fait par un outil très utilisé qui s'appelle une \acrshort{API} (\textit{\acrlong{API}}). Une telle interface facilite la communication entre deux ordinateurs pour qu'ils puissent échanger d'information. Ainsi, un ordinateur peut demander aux serveurs de la \acrlong{BNF} les images d'un document source qu'ils conservent.

Il y a beaucoup de types d'\acrshort{API}, chacune programmée pour parler certains langages de requête et pour communiquer certains types d'information. Une \acrshort{API} destinée à la communication des données visuelles, surtout les fac-similés numériques du patrimoine, a été développée par \textit{l'\Gls{iiif}} (\acrshort{IIIF}). Le \acrshort{IIIF} s'engage à standardiser la gestion des ressources visuelles mises en ligne avec le but d'améliorer l'exploitation et l'échange des ressources et de leurs métadonnées. Suite à une requête HTTP(S) standardisée, c'est-à-dire un URI (\textit{Uniform Resource Identifier}) qui commence par \og{}\texttt{https://}\fg{}, l'\Gls{iiifapi} transfère les données visuelles requêtées vers l'ordinateur de l'expéditrice ou de l'expéditeur. L'URI se compose de quatre éléments génériques suivis par cinq éléments qui précisent (1) la région, (2) la taille, (3) la rotation, (4) la qualité, et (5) le format de l'image demandée.


\begin{figure}[htp]
\centering
%%%%% Start of Image API URI
\begin{subfigure}[b]{0.4\textwidth}
\centering
\begin{tabular}{|c||l|} 
\hline
scheme & \texttt{https://} \\ \hline
server & \texttt{gallica.bnf.fr}\\ \hline
prefix & \texttt{/iiif}\\ \hline
identifier & \texttt{/ark:12148/bpt6k1057726c}\\ \hline
folio & \texttt{/f1}\\ \hline
region & \texttt{/full}\\ \hline
size & \texttt{/full}\\ \hline
rotation & \texttt{/0}\\ \hline
quality & \texttt{/native}\\ \hline
format & \texttt{.jpg}\\ \hline
\end{tabular}
\caption{URI pour l'IIIF Image API}
\label{fig:uri-imageapi}
\end{subfigure}
%%%%% End of Image API URI
\hfill
%%%%% Start of Presentation API URI
\begin{subfigure}[b]{0.4\textwidth}
\centering
\begin{tabular}{|c||l|} 
\hline
scheme & \texttt{https://} \\ \hline
server & \texttt{gallica.bnf.fr}\\ \hline
prefix & \texttt{/iiif}\\ \hline
identifier & \texttt{/ark:12148/bpt6k1057726c}\\ \hline
manifest & \texttt{/manifest}\\ \hline
format & \texttt{.json}\\ \hline
\end{tabular}
\caption{URI pour l'IIIF Presentation API}
\label{fig:uri-presentationapi}
\end{subfigure}
%%%%% End of Presentation API URI

\hspace{0.3\textwidth}%

%%%%% Start of API Diagram
\begin{subfigure}[b]{\textwidth}
\tikzstyle{source} = [cylinder, draw=black, thick, aspect=0.7, minimum height=1.7cm, minimum width=2cm, text width=2cm, text centered, fill=blue!10]
\tikzstyle{api} = [rectangle, minimum width=2cm, minimum height=1.7cm,text centered, draw=black, fill=gray!30, text width=2.25cm]
\tikzstyle{objet} = [rectangle, rounded corners, minimum height=1.7cm, text centered, draw=black, text width=1.7cm]
\tikzstyle{url} = [rectangle, minimum height=1.7cm, draw=black, text width=4cm, text centered, fill=yellow!30]
\tikzstyle{arrow} = [thick,->,>=stealth]
\begin{center}
\begin{tikzpicture}

\node[source] (server) {Serveur d'images};
\node[source, below = of server] (metadata) {Source des métadonnées};
\node[api, right = of server] (imageapi) {IIIF Image API};
\node[objet, right = of imageapi] (image) {Image (JPEG)};
\node[objet, right, below = of image] (data) {Données (JSON)};
\node[api, right = of image] (presentationapi) {IIIF Presentation API};
\node[objet, right = of presentationapi] (end) {Browser};
\node[url, above = of imageapi] (imagerequest) {URI pour l'IIIF Image API};
\node[url, above = of presentationapi] (presentationrequest) {URI pour l'IIIF Presentation API};
\draw[arrow] (server) -- (imageapi);
\draw[arrow] (metadata) -- (data);
\draw[arrow] (imageapi) -- (image);
\draw[arrow] (image) -- (presentationapi);
\draw[arrow] (data) -- (presentationapi);
\draw[arrow] (presentationapi) -- (end);
\draw[arrow]  (imagerequest) -- (imageapi);
\draw[arrow] (presentationrequest) -- (presentationapi);

\end{tikzpicture}
\end{center}
\caption{IIIF Image API et IIIF Presentation API}
\label{fig:apis}
\end{subfigure}
%%%% End of API diagram
\caption{IIIF APIs}
\label{fig:api}
\end{figure}

Puisque la \acrshort{BNF} s'engage à l'initiative de l'\acrshort{IIIF}, toute page numérisée qui se conserve sur sa base de données Gallica peut être requêtée par l'URI que l'\Gls{iiifapi} attend. La Figure~\ref{fig:api} montre comment construire les URIs afin d'acquérir les données visuelles du portail Gallica. Prenons le document source de l'identifiant \acrshort{ARK} bpt6k1057726c, par exemple. Pour récupérer ses pages numérisées depuis la base de données Gallica, on envoie une requête à l'\Gls{iiifapi}~; l'exemple pour récupérer la totalité de la première page du document en format JPEG, sans rotation ni d'autre modification, se voit dans la Figure~\ref{fig:uri-imageapi}. Comme la Figure~\ref{fig:apis} visualise, une telle requête HTTPS envoyée à l'\Gls{iiifapi} renverra un objet numérique de l'image. Afin d'accès aux métadonnées de l'image, on enverrait une requête d'une autre structure à la Presentation \acrshort{API}, montrée dans la Figure~\ref{fig:uri-presentationapi}, qui renverrait des données en format \acrshort{JSON}.

\subsection{La mise en pratique}
Dans le cadre du projet \textsc{Artl@s} en 2020, Caroline Corbières a développé un script pour importer à partir de l'\Gls{iiifapi} les pages d'un fac-similé numérique stocké sur les serveurs de la \acrshort{BNF}\footcite{gabayAutomatingArtlExtracting2021}. Le projet \textit{Gallic(orpor)a} a profité du travail de Corbières et l'a utilisé pour récupérer des fac-similés numériques ciblés par l'utilisatrice ou l'utilisateur du pipeline. En ajoutant une option au script (\texttt{-l}) je l'ai modifié afin de permettre qu'une utilisatrice ou utilisateur puisse limiter les nombres de pages récupérées. La limite évite le téléchargement de trop d'images ainsi qu'économise l'énergie dépensée. Ainsi, l'utilisatrice ou l'utilisateur peut tester la mise en œuvre des modèles \acrshort{HTR} ou \acrshort{TAL} sur un panel restreint des données.

\section{L'application des modèles HTR}
Le pipeline du projet \textit{Gallic(orpor)a} vise à transcrire les ressources textuelles avec un modèle \acrshort{HTR} qui convient bien au type du document, en rappelant qu'un modèle se spécialise dans une écriture particulière grâce à son entraînement. Cela exige donc que le pipeline se dispose des modèles entraînés et qu'il prend sa décision automatiquement sur quel modèle convient auquel document traité. Lors de l'installation du pipeline, l'utilisatrice ou l'utilisateur fournit des modèles à mettre en œuvre\footnote{Le pipeline peut s'adapter aux divers modèles et mettre en œuvre tout modèle \acrshort{HTR} qu'une utilisatrice ou un utilisateur lui donne lors de l'installation du pipeline s'il est basé sur l'engin \textit{Kraken}. En s'adaptant aux modèles publiés ainsi qu'aux modèles toujours en cours qu'une utilisatrice ou un utilisateur lui donne directement, selon sa configuration pendant l'installation, le pipeline facilite les expériences scientifiques sur plusieurs corpus.}. En outre, l'utilisatrice ou l'utilisateur désigne un modèle de segmentation et celui de \acrshort{HTR} par défaut, que le pipeline utiliserait s'il ne pensait pas que les autres modèles installés conviennent bien au document qu'il est en train de traiter. En plus de mettre en pratique des modèles \acrshort{HTR}, le projet \textit{Gallic(orpor)a} vise à en construire des nouveaux.

\subsection{L'entraînement des modèles}
Dans le cadre du projet \textit{Gallic(orpor)a}, l'équipe a entraîné des nouveaux modèles généralistes, l'un pour les manuscrits et les incunables en français, l'autre pour les imprimés françaises créées avant la révolution. Ces modèles ont besoin des vérités de terrain produites lors du projet \textit{Gallic(orpor)a}. Bien que le pipeline ne refasse pas la création de ces vérités de terrain, ni de l'entraînement des modèles, il profite de cet objectif parallèle du projet puisque le pipeline a besoin de modèles très performants.

\subsubsection{La création des vérités de terrain}
Lors de la première moitié de 2022, l'équipe du projet \textit{Gallic(orpor)a} se composait des vacataires qui se chargeaient de la création des vérités de terrain pour les nouveaux modèles \acrshort{HTR}. Les chefs du projet Simon Gabay et Ariane Pinche ont sélectionné un corpus de documents à transcrire. Les membres de l'équipe se spécialisaient dans certains types de document présents sur la liste, tel qu'un incunable du Moyen Âge. Un vacataire prend l'un des documents du corpus et saisit son identifiant \acrshort{ARK} dans l'interface de transcription \textit{eScriptorium}, dont je parle dans le chapitre~\ref{chap:htr}. L'interface imite ce que le pipeline \textit{Gallic(orpor)a} fait, ainsi que le script de Corbières, en téléchargeant les images du document depuis l'\Gls{iiifapi} de la \acrshort{BNF}.

L'interface \textit{eScriptorium} facilite la segmentation et la transcription des pages. Les vacataires l'utilisent pour segmenter les zones de la page et y mettre les étiquettes conformant au vocabulaire \textit{SegmOnto}. Portant les étiquettes de \textit{SegmOnto}, les transcriptions aident à entraîner les modèles avec un vocabulaire cohérent pour tout type de document, y compris les manuscrits et les imprimés. L'interface \textit{eScriptorium} export les vérités de terrain dans un fichier \acrshort{XML} \acrshort{ALTO} avec des images téléchargés en format JPEG ou PNG.

\subsection{La sélection des modèles}
Dans l'intérêt de maximiser l'automatisation du pipeline, la mise en œuvre d'un modèle s'effectue automatiquement, selon une analyse des métadonnées du document à traiter. J'ai réalisé l'attribution automatique des bons modèles aux documents grâce à deux idées~: le modèle par défaut et le modèle idéal. Dans un premier temps, le pipeline récupère les métadonnées \acrshort{IIIF} du fac-similé numérique qui portent sur sa langue et sa date de création. Ensuite, j'ai cherché dans les modèles installés avec le pipeline s'il y en a un qui a été entraîné sur les données de la même langue et du même siècle. S'il n'y en a pas, le pipeline utilise son modèle par défaut. Soit l'utilisatrice ou l'utilisateur du pipeline déclare le modèle par défaut selon ses besoins, soit le modèle par défaut programmé en dur dans le pipeline est utilisé, au cas où l'utilisatrice ou l'utilisateur n'en précise aucun. Disposé de l'attribution automatique du modèle, le pipeline peut traiter beaucoup de documents d'une diachronie longue, sans besoin d'intervention d'une personne à chaque application du modèle \acrshort{HTR}.

\subsection{La sortie des modèles segmentation et HTR}
Les modèles \acrshort{HTR} basés sur \textit{Kraken} produisent des fichiers \acrshort{XML} qui conforment soit au schéma \acrshort{ALTO}, soit au schéma PAGE. Les deux schémas sont bien adaptés à l'encodage des données portant sur la mise en page et sur la transcription d'un texte. L'équipe de \textit{Gallic(orpor)a} a privilégié le schéma \acrshort{ALTO} puisqu'il accorde plus de détail sur la mise en page. 
La \acrlong{BNF} le décrit comme comme, \og{}un schéma \acrshort{XML} standardisé, qui permet de stocker les informations relatives à la structure physique et au texte extrait par \acrshort{OCR}\fg{}\footcite[75]{caronFormatsDonneesPour2021}. 
Par rapport au schéma PAGES, le schéma \acrshort{ALTO} conserve plus de données produites par le modèle de segmentation, tout en gardant leur relation aux données textuelles produites par le modèle \acrshort{HTR}.

\subsection{Le schéma ALTO}
Le schéma \acrshort{ALTO} a été développé dans le cadre du projet METS (\textit{Metadata Encoding and Transmission Schema}). Le dernier date de 2001\footcite{METSMetadataEncoding}. Comme résume la \acrlong{BNF},
\begin{displayquote}METS renseigne alors sur la structure logique de la page (nature sémantique des blocs de texte, par exemple titre, partie d'article, légende d'illustration, etc.), tandis qu'ALTO localise des contenants (blocs, lignes, etc.) sur la matrice de l'image de la page\footcite[75]{caronFormatsDonneesPour2021}.
\end{displayquote}
Le schéma \acrshort{ALTO} vise donc à renseigner sur la mise en page ainsi que sur le texte d'une page. Certains de ses éléments, tel que l'élément \texttt{<polygon>}, précisent les coordonnées d'une région ou d'une zone sur la page qu'avait prédite un modèle de segmentation. Cependant, certains attributs, tel que l'attribut \texttt{@CONTENT}, sont associés à la prédiction du texte. Prenons l'exemple montré dans la Figure~\ref{fig:alto} où le schéma \acrshort{ALTO} encode une phrase incomplète~: \textit{oyseaux lesquelz ie esperoye pren}. Les données imbriquées dans l'élément \texttt{<TextLine>} parviennent à porter sur la mise en page de la ligne ainsi que sur son texte. La puissance du schéma \acrshort{ALTO} est sa manière de combiner ses deux types d'information.

Dans la Figure~\ref{fig:alto}, les quatre points du rectangle qui encadre la ligne de texte sont données par les attributs de l'élément \texttt{<TextLine>}~: \texttt{@HPOS}, \texttt{@VPOS}, \texttt{@WIDTH}, \texttt{@HEIGHT}. Puisque le modèle de segmentation a aussi encadré la ligne de texte dans un polygone, tous les points de l'objet sont données par l'attribut \texttt{@POINTS} de l'élément \texttt{<Polygon>}. Le schéma \acrshort{ALTO} renseigne aussi sur le \textit{baseline} de la ligne de texte en donnant les coordonnées x,y du début et de la fin dans l'attribut \texttt{@BASELINE}. En plus de ces données structurelles, le schéma permet d'encoder les données textuelles dans l'attribut \texttt{@CONTENT} de l'élément \texttt{<String>}, où se trouve la ligne de texte \textit{oyseaux lesquelz ie esperoye pren}.

\begin{figure}[ht]
\centering
\begin{lstlisting}[language=XML]
<TextLine	ID="eSc_line_1ed06324"
    TAGREFS="LT825"
    BASELINE="1193 982 2263 969"
    HPOS="1184"
    VPOS="877"
    WIDTH="1079"
    HEIGHT="127">
    <Shape>
        <Polygon POINTS="1193 982 1184 903 1303 877 1307 877 2255 890 2263 969 2263 995 1193 1004"/>
    </Shape>
    <String
        CONTENT="oyseaux lesquelz ie esperoye pren"
        HPOS="1184"
        VPOS="877"
        WIDTH="1079"
        HEIGHT="127">
    </String>
</TextLine>
\end{lstlisting}
\caption{L'encodage d'une ligne de texte en ALTO}
\label{fig:alto}
\end{figure}

L'encodage vu dans la Figure~\ref{fig:alto} ne représente pas tout manière d'encoder une ligne de texte possible dans le schéma \acrshort{ALTO}. Le schéma peut se réaliser avec plusieurs niveaux de détail. Par exemple, le contenu de la ligne de texte peut être désagrégé au point que chaque segment du texte se trouve dans son propre élément \texttt{<String>} descendant du \texttt{<TextLine>}. Comme cela, les coordonnées de chaque mot peut être précisées. Ce format plus détaillé est celui produit depuis la ligne de commande (CLI, ou \textit{Command Line Interface}) de \textit{Kraken}\footnote{En traitant les fichiers \acrshort{XML} \acrshort{ALTO} sortis de la ligne de commande, il doit reconstruire le contenu de la ligne de texte à partir de plusieurs éléments \texttt{<String>} qui représentent les mots dans une ligne de texte, au lieu de la ligne de texte elle-même.}. Le format montré par la Figure~\ref{fig:alto}, le moins détaillé, est celui utilisé par l'interface \textit{eScriptorium}. L'un des défis du pipeline est de s'adapter aux divers formats d'\acrshort{ALTO} qu'un logiciel \acrshort{HTR} pourrait produire.

\section{Réunir la transcription et les métadonnées}
Jusqu'ici, le pipeline a récupéré les images numériques en format JPEG ou PNG depuis l'\Gls{iiifapi} et les a traité avec les modèles \acrshort{HTR} en produisant des fichiers \acrshort{XML} \acrshort{ALTO}. Ensuite, le pipeline recherchera les métadonnées en plusieurs formats, y compris \acrshort{JSON}, \acrshort{XML}, et \acrshort{HTML}, depuis l'internet. Avec une telle diversité de structures de données, un format robuste est exigé pour tout rassembler et le mettre en ordre. L'équipe de \textit{Gallic(orpor)a} a choisi de s'appuyer sur un fichier \acrshort{XML}, où les données sont imbriquées dans une façon hiérarchisée, mais du schéma \acrshort{TEI}.  Contrairement au schéma \acrshort{ALTO}, le schéma \acrshort{TEI} se spécialise dans l'édition numérique du texte. La communauté du \acrshort{TEI} décrit l'objectif du projet ainsi~:
\begin{displayquote}
\textit{The Text Encoding Initiative (TEI) is a consortium which collectively develops and maintains a standard for the representation of texts in digital form. Its chief deliverable is a set of Guidelines which specify encoding methods for machine-readable texts, chiefly in the humanities, social sciences and linguistics}\footcite{TEITextEncoding}.
\end{displayquote}
En plus de la représentation numérique du texte, la \acrshort{TEI} dispose des éléments \acrshort{XML} qui conviennent bien à la représentation de la mise en page. La \acrshort{TEI} est donc un format idéal pour fusionner les transcriptions sorties des modèles \acrshort{HTR}, les métadonnées récupérées des sources en ligne, et le texte extrait des transcriptions. En plus, la \acrshort{TEI} est un format très utilisé et beaucoup d'outils numériques s'y adaptent déjà. 

\subsection{L'extrait des données des fichiers \acrshort{ALTO}}
\label{firstMentionSourceDoc}
Les données sorties du traitement \acrshort{HTR} sont du schéma \acrshort{XML} \acrshort{ALTO} mais le pipeline \textit{Gallic(orpor)a} veut se terminer par un document \acrshort{TEI}. Il faut donc transformer la sortie des modèles \acrshort{HTR} en le format souhaité en ajoutant des métadonnées récupérées depuis plusieurs sources de données externes. En plus de mettre en œuvre un prototype du pipeline entier, je me suis chargée de la modélisation d'\acrshort{ALTO} à \acrshort{TEI}. Le livrable principal de mon stage est l'application \texttt{alto2tei}\footcite{christensenGallicorporaApplication}.

Nous de l'équipe de \textit{Gallic(orpor)a} avons conclu que l'élément \acrshort{XML} \acrshort{TEI} \texttt{<sourceDoc>} convient bien à l'encodage de toute donnée des modèles \acrshort{HTR} portant sur le texte prédit et de la mise en page. Des autres chercheurs, tel que Hugo Scheithauer, Alix Chagué, et Laurent Romary, ont arrivés à la même conclusion\footcite{scheithauerEScriptoriumTEIPublisher2021}. Les \textit{guidelines} de la \acrlong{TEI} définissent l'élément \texttt{<sourceDoc>} ainsi~:
\begin{displayquote}
\texttt{<sourceDoc>} \textit{contains a transcription or other representation of a single source document potentially forming part of a dossier génétique or collection of sources}\footcite{TEIElementSourceDoc}.
\end{displayquote}
Les données structurelles et textuelles de la page numérisée sont balisés dans les éléments \acrshort{XML} descendant du \texttt{<sourceDoc>}. Ces choix sont décrits et justifiés dans le chapitre~\ref{chap:xml}.

\subsection{Le récupération des métadonnées}
En plus de transformer les données des fichiers \acrshort{ALTO}, le pipeline récupère les métadonnées portant sur le fac-similé numérique, le document source physique qui a occasionné la création du fac-similé, ainsi que la ressource numérique sortie du pipeline lui-même. Toutes ses métadonnées sont encodées dans l'élément \acrshort{XML} \acrshort{TEI} \texttt{<teiHeader>}. Comment réussit le pipeline à récupérer les métadonnées qui ne sont pas données par les fichiers \acrshort{ALTO}~? Avec l'identifiant \acrshort{ARK}, qu'il prend du système de fichiers, le pipeline récupère dans un premier temps les métadonnées du fac-similé numérique, dont les images les modèles \acrshort{HTR} ont traité. Même pour les fac-similés hébergés par divers institutions, le pipeline récupère les métadonnées diffusées directement par l'\acrshort{API} \acrshort{IIIF}..

Créée dans le cadre du projet \textit{Gallic(orpor)a}, l'application \texttt{alto2tei} récupère les métadonnées qui portent sur le document source physique grâce à une relation qui se donne entre le fac-similé numérique sur Gallica et le document source physique conservé par la \acrshort{BNF}. L'application demande cette relation de l'\acrshort{API} \acrshort{IIIF} que la \acrshort{BNF} met à disposition. Si elle est bonne, l'application passe ensuite par l'\acrshort{API} \acrshort{SRU} de la \acrshort{BNF}. Ce genre d'\acrshort{API} renvoie des données hiérarchisées dans un schéma \acrshort{XML}. En anglais, son nom veut dire \textit{\acrlong{SRU}} (SRU). Enfin, le pipeline recherche encore des métadonnées dans le catalogue du \acrlong{SUDOC}(\acrshort{SUDOC}) qui portent sur les institutions patrimoniales en France qui hébergent des documents sources.

\subsection{La construction du document préliminaire TEI}
La première étape de la construction du document \acrshort{TEI} est la récupération des données, à la fois depuis les fichiers \acrshort{XML} \acrshort{TEI} et les sources de données externes. Les données de la transcription sont représentées dans l'élément \texttt{<sourceDoc>} du document \acrshort{TEI}, les métadonnées dans son élément \texttt{<teiHeader>}. Ensuite, la deuxième étape est le traitement des données ainsi extraites et nettoyées des fichiers \acrshort{ALTO}. D'abord, le pipeline extrait toute ligne de texte et la balise dans le bon élément \acrshort{TEI} intégré dans le \texttt{<body>}.

\section{L'analyse linguistique et le fichier final}
L'avant dernier étape du pipeline est d'analyser le texte récupéré et intégré dans le \texttt{<body>}. D'abord, le pipeline colle des lignes de texte en des phrases complètes. Ensuite, il met en œuvre des modèles \acrshort{TAL} pour tokéniser et analyser le texte. La tokénisation divise la phrase en composants (\textit{tokens} ou lexèmes). Une autre analyse linguistique, la lemmatisation traite les \textit{tokens} ainsi distingués. Tout \textit{token} pourrait ensuite être normalisé par un modèle \acrshort{TAL} qui transforme le mot prédit par le modèle \acrshort{HTR} en sa version normalisée. Par exemple, un modèle \acrshort{TAL} de normalisation peut transformer le mot prédit \textit{nostre} en le mot normalisé \textit{nôtre}, comme montré par les expériences de Rachel Bawden et son modèle FREEMnorm\footcite{bawdenAutomaticNormalisationEarly2022}. Enfin, un modèle \acrshort{TAL} NER (\textit{Named-Entity Recognition}) peut encore traiter le texte pour reconnaître les entités nommées, tel qu'une personne ou un lieu. Le pipeline met en œuvre plusieurs modèles \acrshort{TAL} afin d'analyser ses divers aspects linguistiques du texte.

\subsection{L'\acrshort{ODD} (\Gls{odd}}
Un fichier \acrshort{TEI} se soumettent aux règles qui assurent l'uniformité. Afin de mettre en pratique les traitements à l'échelle pour tout document produit par le pipeline, il faut que tout élément \acrshort{TEI} soit utilisé de la même manière. Pour parvenir à une telle régularité, la \acrshort{TEI} dispose d'un document qui applique des règles personnalisées au produit souhaité du pipeline. Ce document se connaît par son acronyme \acrshort{ODD}, qui veut dire \textit{\Gls{odd}} ou un fichier qui tout fait. Dans le cadre du stage, j'ai aidé à la rédaction d'un \acrshort{ODD} qui explique en détail tout aspect du document \acrshort{TEI} sorti du pipeline.

\section{L'exploitation des données}
Enfin, les données encodées dans le fichier \acrshort{TEI} enrichi et final peuvent être exploitées en tant qu'un fichier \acrshort{XML} \acrshort{TEI} ainsi que dans divers formats secondaires. Le logiciel TEI Publisher, par exemple, peut aisément publier un fichier \acrshort{XML} \acrshort{TEI} et permettre les utilisateurs de naviguer les données dans un visionneur de l'édition en ligne\footcite{EeditionesTeipublisherapp2022}. Le document \acrshort{TEI} peut aussi être exploité par les fichiers de transformation XSL. Il y a plusieurs formats secondaires qui pourraient servir à l'exploitation des données encodées dans le fichier \acrshort{XML} \acrshort{TEI}.

L'équipe envisage trois formats secondaires par lesquels les données produites par le pipeline peuvent être exploitées. L'un de ses formats est l'\acrshort{IIIF}, le même qui a permis la construction du document \acrshort{TEI} dans un premier temps. Tout attribut \texttt{@source} dans le \texttt{<sourceDoc>} du document \acrshort{TEI} contient un URI qui permet de visionner la partie de l'image concernée. Par exemple, si l'attribut \texttt{@source} descend d'un élément \texttt{<zone>} qui porte sur une ligne de texte, sa valeur donnerait dans un browser ou dans un visionneur uniquement la partie de l'image source qui contient cette ligne de texte. Ainsi, les données du fichier \acrshort{XML} \acrshort{TEI} final peuvent être exploitées afin de visionner les bloques de textes, lignes de textes, les mots, et les caractères transcrits. Les deux autres formats secondaires profitent plutôt des métadonnées du fichier \acrshort{TEI}~; ils sont le \acrshort{DTS} (\acrlong{DTS}) et le \acrshort{RDF} (\acrlong{RDF}).

\end{document}
\documentclass[../main.tex]{subfiles}